{"nbformat":4,"nbformat_minor":4,"metadata":{"colab":{"collapsed_sections":[],"name":"DL20-fall-seminar6.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Yandex DataSphere Kernel","language":"python"},"language_info":{"pygments_lexer":"ipython3","file_extension":".py","version":"3.7.7","mimetype":"text/x-python","codemirror_mode":{"version":3,"name":"ipython"},"name":"python","nbconvert_exporter":"python"},"notebookId":"fd0e9dab-5c8c-4772-838c-b015ccaa1776"},"cells":[{"cell_type":"markdown","source":"# Нейросети в задачих обработки текстов\n\nОсновано на коде из курса [Глубинное обучение ФКН](https://github.com/aosokin/dl_cshse_ami).\n\n**Разработчик: Алексей Озерин, Ирина Сапарина**","metadata":{"id":"Dv2skd3-53rx","cellId":"47ryuvby7qkjs8e868srzq"}},{"cell_type":"markdown","source":"# Генерация коротких текстов с помощью RNN и Transformer\n\n\nГенерировать тексты можно как с помощью RNN, так и с помощью Transformer, предсказывая следующий символ последовательности по предыдущим. Мы будем использовать архитектуру Transformer.\n\nВ этом задании предлагается написать и проучить на небольшом датасете имен генеративную модель на основе символов.","metadata":{"id":"ozLuJF3kIaPF","cellId":"68o6k1nb2i6e7p042cmfxb"}},{"cell_type":"code","source":"%matplotlib inline\n\nimport numpy as np\nimport random\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\nfrom torch import optim\nfrom torch.utils.data import Dataset, DataLoader, Sampler\nfrom tqdm.auto import tqdm\nfrom torch.utils.tensorboard import SummaryWriter\n\nfrom IPython.display import clear_output\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport datetime\nimport os\nfrom copy import deepcopy\nfrom collections import defaultdict, OrderedDict\n\nrandom.seed(2021)\nnp.random.seed(2021)\ntorch.manual_seed(2021)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed_all(2021)","metadata":{"id":"a_s_Z5lbIaPG","cellId":"yxhturx48eg1cvprm0ymj","trusted":true},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"В файле `names` находится ~8k имен на латинице.\n\nМодель будет получать на вход имя `Amandy` и выдавать его же, только со сдвигом: `mandy `.\n\nЧтобы сеть училась генерировать заглавные буквы, добавим в начало специальный токен `_`.\n\nТакже нам потребуется правило для останова генерации (это может быть просто ограничение на количество шагов). С другой стороны, можно добавить в конец каждого примера обучающей выборки специальный `<EOS>` токен. В данном случае обозначим его `#`:\n\n```\n_Amandy --> Amandy#\n```\n\nМожно прекращать генерацию при досрочном выпадании `<EOS>`.\n\nДля генерации на каждом шаге будем подавать на вход букву, предсказанную на предыдущем.\n\n","metadata":{"id":"n6nXxU8WIaPM","cellId":"ec5vema5tomq52wrrxl76"}},{"cell_type":"code","source":"import os\nstart_token = \"_\"\neos = '#'\n\nwith open(\"names\") as f:\n    names = f.readlines()\n    names = [start_token + name.strip() + eos for name in names]\n\nnames = list(set(names))  # в датасете есть повторы\nprint('There are {} names: '.format(len(names)))\nfor x in names[::1000]:\n    print(x)","metadata":{"id":"TFRHva2zIaPN","cellId":"ij284yylgafqnvlzj9eix","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"There are 7578 names: \n_Wolf#\n_Lolly#\n_Amy#\n_Grete#\n_Reuven#\n_Nanice#\n_Nikoletta#\n_Olenka#\n"}],"execution_count":2},{"cell_type":"markdown","source":"# Подготовка и знакомство с данными\n**(0.1 балла)**","metadata":{"id":"RizB5cBTIaPP","cellId":"u5fwlovps7hkgmixxcqyrh"}},{"cell_type":"code","source":"# TODO: постройте частоты употреблений букв\ndic = defaultdict(int)\nfor name in names:\n    for letter in name:\n        dic[letter] +=1\n        \nordered = dict(sorted(dic.items(), key=lambda item: item[1], reverse=True))\n\nplt.figure(figsize=(10,10))\nplt.bar(x=ordered.keys(), height=ordered.values())\nplt.show()\n# HINT: для графика возьмите plt.bar","metadata":{"id":"DSve0HBaIaPS","cellId":"6q2bbaicismanqpinrco7s","trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 720x720 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}],"execution_count":3},{"cell_type":"code","source":"# в датасете есть слова с разными длинами\nMAX_LENGTH = max(map(len,names))\nprint(\"max length =\", MAX_LENGTH)\n\nplt.title('Sequence length distribution')\nplt.hist(list(map(len,names)), bins=25);","metadata":{"id":"QAeSKss4IaPV","cellId":"51o1063jdqv4zdt9onyqvu","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"max length = 17\n"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}],"execution_count":4},{"cell_type":"code","source":"names[:10]","metadata":{"id":"cWnDPWr9IaPY","cellId":"1r32f8ycpzs0co3jz3la7n","trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"['_Wolf#',\n '_Yancey#',\n '_Willow#',\n '_Zachariah#',\n '_Mady#',\n '_Maynard#',\n '_Ferguson#',\n '_Rosana#',\n '_Tami#',\n '_Stu#']"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"# TODO: отберите уникальные токены и заполните два словаря для конвертации токенов <-> индексы\n# сделайте так, чтобы pad_token имел номер 0\n    \ntokens = ordered.keys()\n    \ntok2id = {tok: i for i, tok in enumerate(tokens)}\nid2tok = {i: tok for i, tok in enumerate(tokens)}\n\nn_tokens = len(tokens)\nprint ('There are {} tokens'.format(n_tokens))\n\nassert 50 < n_tokens < 60\n\nprint('Vocabular: ' + \"\".join(tokens))","metadata":{"id":"zgB0VE9BIaPa","cellId":"lozopognh1oe7bx3u7nya","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"There are 57 tokens\nVocabular: _#eainrlotsydhumMcACSbDRLJgBETGKvkHNFfPpWwVIOzZxjUq-YQX '\n"}],"execution_count":6},{"cell_type":"markdown","source":"## Работа с последовательностями произвольной длины в pytorch\n\nНам нужно уметь генерировать батчи тензоров `[bs, 1, seq_len]`.\nНо в нашем датасете семплы разной длины:\n\n- мы могли бы подрезать все до минимальной\n- паддить до максимальной\n- выбрать какую-то среднюю длину\n\n**(0.1 балла)** Разбейте датасет на train и validate:","metadata":{"id":"fW62jy6xIaPm","cellId":"0f64s9luecgbl684m0q3pt8"}},{"cell_type":"code","source":"#!g1.1\n# сделаем датасет выдающий закодированные имена:\nclass NamesDataset(Dataset):\n    def __init__(self, names):\n        self.names = names\n    \n    def __len__(self):\n        return len(self.names)\n    \n    def __getitem__(self, item):\n        entry = self.names[item]\n        lst = []\n        for letter in entry:\n            lst.append(tok2id[letter])\n        while len(lst) < 10:\n            lst.append(tok2id[' '])\n        entry = torch.tensor(lst[:10])\n        return dict(\n            encoded=entry,\n        )\n\n# Вот тут я вообще ничего не понял, по идеи tok2id - это словарь, в котором токены переводятся в индексы. Но словари так не вызываются\n# получаю естественно ошибку TypeError: 'dict' object is not callable\n# поскольку непонятна изначальная задумка, то сделаю по-своему и предобработку имен сделаю в датасете.\n\n# encoded = []\n# for entry in tqdm(names):\n#     encoded.append(tok2id(entry))\n\n\ndef train_val_split(names, train_size=0.85):\n    train = np.random.choice(names, size=int(train_size * len(names)), replace=False)\n    val = np.setdiff1d(np.array(names), train)\n    return train, val\n\ntrain_names, val_names = train_val_split(names)\n    \ntrainset = NamesDataset(train_names)\nvalset = NamesDataset(val_names)","metadata":{"cellId":"qr2kzd65zxdgeb7chcjyhq","trusted":true},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"Давайте соберем наивный DataLoader и посмотрим как он делает батчи:\n","metadata":{"cellId":"x6pccwztqri3a0b7b19rm2"}},{"cell_type":"code","source":"#!g1.1\ntrainloader = DataLoader(trainset, batch_size=8, shuffle=True)\nit = iter(trainloader)","metadata":{"cellId":"a3igawv0dxjoi9t1i0ljr9","trusted":true},"outputs":[{"output_type":"stream","name":"stderr","text":"/kernel/lib/python3.7/site-packages/ml_kernel/kernel.py:811: UserWarning: The following variables cannot be serialized: it\n  warnings.warn(message)\n"}],"execution_count":8},{"cell_type":"code","source":"#!g1.1\nbatch = next(it)['encoded']\nbatch","metadata":{"cellId":"1v442xp7tkdxd97yyxpaq8","trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"tensor([[ 0, 43, 10,  4, 12,  8,  6,  2,  1, 55],\n        [ 0, 34,  3, 10, 10,  3,  5,  1, 55, 55],\n        [ 0, 25, 11,  8,  9,  4,  1, 55, 55, 55],\n        [ 0, 18, 15,  3,  5, 12,  4,  2,  1, 55],\n        [ 0, 40,  4,  7,  9,  1, 55, 55, 55, 55],\n        [ 0, 40,  2, 11,  7,  4,  5,  1, 55, 55],\n        [ 0, 23,  3, 11, 15, 14,  5, 12,  8,  1],\n        [ 0, 24,  8,  6,  4,  1, 55, 55, 55, 55]])"},"metadata":{}},{"output_type":"stream","name":"stderr","text":"/kernel/lib/python3.7/site-packages/ml_kernel/kernel.py:811: UserWarning: The following variables cannot be serialized: it\n  warnings.warn(message)\n"}],"execution_count":9},{"cell_type":"markdown","source":"В моем случае, результат запуска был таков:\n```\n[tensor([1, 1, 1, 1, 1, 1, 1, 1]),\n tensor([ 6,  7,  6, 15,  5,  6,  5, 62]),\n tensor([ 48,  34,  83,   7,  32, 221,  22,  43]),\n tensor([  5, 143,  37,  36, 129,  12,  11,  66]),\n tensor([  73, 1258,  279,    8,    6,  555,   41,   10]),\n tensor([  8, 140,   8, 628,  20,  96,  13, 270]),\n tensor([  47,    4,   15,   18,   55,  269,    6, 1287]),\n tensor([ 58,   2,  13, 140, 193, 140, 171, 140])]\n```\n\nКакие странности здесь видны?\n1. Это не тензор, а список тензоров. Соответственно при итерировании по нулевой размерности (`batch[i, :]`) мы будем получать не i-пример, а i-токены для всех примеров в батче. Это не проблема, но отличается от ожидаемого поведения.\n2. На `<EOS>` (2) оканчивается только один пример, остальные подрезаны под его длину. И вот это уже проблема.\n\nМы бы хотели западдить все примеры до длины максимального в батче. \nНо на этапе подготовки примера (в функции `__getitem__`) мы не знаем соседей по батчу!\nДля того чтобы поменять логику склейки батчей нам понадобиться написать свою функцию `collate_fn` в конструкторе DataLoader:\n\n```\ndef collate_fn(samples):\n    # samples -- список семплов-словарей\n    <...>\n    return batch\n```\n\n**(0.1 балл)** Напишите функцию `collate_fn`, которая _правильно_ паддит names-последовательности и объединяет их в батчи, где `batch[i, :]` выдает токены для `i`-примера.\n\nОжидаемый выход (для последовательности с левым паддингом):\n\n```\ntensor([[   1,   10, 3429,  405,  113,  676,   10, 1031,  140,    4,    2],\n        [   0,    1,   57,   18,   23,   19,   61,    7,  140,    4,    2],\n        [   0,    0,    0,    1,   16,   17, 1131,  416,  140,    4,    2],\n        [   0,    0,    0,    1,   13,  465,   75,  197,  140,    4,    2],\n        [   0,    0,    0,    1,    6,  302,   13,  144,  140,    4,    2],\n        [   0,    1,    6,   59,  205,  167,    8,   15,  140,    4,    2],\n        [   0,    0,    0,    0,    1,    6,   14,  678,  140,    4,    2],\n        [   0,    0,    1,    5,   29,   67,    6,   14,  140,    4,    2]])\n```","metadata":{"cellId":"dhczm5rjfumbrzaipxiby"}},{"cell_type":"markdown","source":"В моем случае нет необходимости в collate_fn, все уже сделано в датасете. Однако, я использую правый паддинг и надеюсь это не проблема","metadata":{"cellId":"yk25q67uhxuvc0chqy5pf"}},{"cell_type":"code","source":"#!g1.1\n# def collate_fn(samples):\n#     # <your code>\n#     return dict(\n#         encoded=...\n#     )\n\n\ntrainloader = DataLoader(trainset, batch_size=8, shuffle=True)\nit = iter(trainloader)\nnext(it)['encoded']","metadata":{"cellId":"f9fv0b6fqbgevcistrhyn","trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"tensor([[ 0, 34,  3, 39, 39, 11,  1, 55, 55, 55],\n        [ 0, 23,  4, 17, 13, 11,  1, 55, 55, 55],\n        [ 0, 31,  4,  1, 55, 55, 55, 55, 55, 55],\n        [ 0, 28,  7, 21,  2,  6,  9,  1, 55, 55],\n        [ 0, 36,  6,  3,  5,  1, 55, 55, 55, 55],\n        [ 0, 44,  6,  3,  7,  2,  2,  1, 55, 55],\n        [ 0, 53, 14,  4,  5,  5,  1, 55, 55, 55],\n        [ 0, 25, 14,  3,  5,  3,  1, 55, 55, 55]])"},"metadata":{}},{"output_type":"stream","name":"stderr","text":"/kernel/lib/python3.7/site-packages/ml_kernel/kernel.py:811: UserWarning: The following variables cannot be serialized: it\n  warnings.warn(message)\n"}],"execution_count":10},{"cell_type":"markdown","source":"# Char-RNN для имен (0.2 балла)\n\nВам нужно написать сеть, кодирующую номера входных символов с помощью таблицы Embeddings. \nПолучившиеся тензоры пропустить через RNN ячейку, затем преобразовать в логиты для предсказания номера нового символа.","metadata":{"cellId":"9865eaquumoc5jn9s4n17u"}},{"cell_type":"code","source":"#!g1.1\n# NB: обратите внимание на порядок осей при вызове forward\n# http://pytorch.org/docs/master/nn.html#recurrent-layers\n\n# Сделайте возможность выбора типа ячейки, RNN, GRU или LSTM\n# TODO: заполните пропуски. Функция forward будет вызываться на каждый шаг нами\n\nclass NameRNN(nn.Module):\n    def __init__(self, vocab_size, hidden_size, output_size, cell=\"lstm\", n_layers=1):\n        super(NameRNN, self).__init__()\n        # добавьте возможность выбрать тип ячейки RNN/LSTM\n        self.vocab_size = vocab_size\n        self.hidden_size = hidden_size\n        self.output_size = output_size\n        self.cell = cell\n        self.n_layers = n_layers\n        \n        self.embeddings = nn.Embedding(vocab_size, hidden_size)\n        self.linear = nn.Linear(hidden_size, output_size)\n\n        if self.cell == 'rnn':\n            self.model = nn.RNN(hidden_size, hidden_size, n_layers)\n        elif self.cell == 'lstm':\n            self.model = nn.LSTM(hidden_size, hidden_size, n_layers)\n        elif self.cell == 'gru':\n            self.model = nn.GRU(hidden_size, hidden_size, n_layers)\n        \n    def forward(self, input, hidden):\n        embeddings = self.embeddings(input).view(self.n_layers, input.shape[0], -1)\n        output, hidden = self.model(embeddings, hidden)\n        out = self.linear(output).view(input.shape[0], -1)\n        return out, hidden\n\n    def init_hidden(self, batch_size):\n        tens = torch.zeros(self.n_layers, batch_size, self.hidden_size)\n        if torch.cuda.is_available():\n            tens = tens.cuda()\n        if self.cell == \"lstm\":\n            return tens, tens\n        return tens\n    \n    def compute_all(self, batch):\n        x = batch['encoded']\n        hidden = self.init_hidden(x.shape[0])\n        loss, acc = 0, 0\n        for i in range(x.shape[1]-1):\n            out, h = self.forward(x[:, i], hidden)\n            loss += F.cross_entropy(out, x[:, i+1])\n            acc += (out.argmax(axis=1) == x[:, i+1]).float().mean().cpu().numpy()\n        metrics = dict(acc=acc/x.shape[0])\n        return loss, metrics","metadata":{"id":"mfGnm2QoIaPo","cellId":"t2tmjgium8o9p0xr4g8bs","trusted":true},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"# Натренируйте модель (0.2 балла)\n\nВозьмите трейнер с предыдущих занятий, натренируйте модель","metadata":{"cellId":"gneajwejvemq53ijdctw1m"}},{"cell_type":"code","source":"#!g1.1\nclass Trainer:\n    def __init__(self, model: nn.Module,\n                 optimizer,\n                 train_dataset: Dataset,\n                 val_dataset: Dataset,\n                 train_sampler: Sampler = None,\n                 val_sampler: Sampler = None,\n                 tboard_log_dir: str = \"results/\",\n                 batch_size: int = 128):\n        self.model = model\n        self.optimizer = optimizer\n        self.train_dataset = train_dataset\n        self.val_dataset = val_dataset\n        self.batch_size = batch_size\n        self.train_sampler = train_sampler\n        self.val_sampler = val_sampler\n\n        self.device = 'cuda'\n        if torch.cuda.is_available():\n            self.device = torch.cuda.current_device()\n            self.model = self.model.to(self.device)\n\n        self.global_step = 0\n        \n        self.train_writer = SummaryWriter(log_dir=tboard_log_dir + \"train/\" \\\n                                          + datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S'))\n        self.val_writer = SummaryWriter(log_dir=tboard_log_dir + \"val/\" \\\n                                        + datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S'))\n        self.cache = self.cache_states()\n\n    def save_checkpoint(self, path):\n        torch.save(self.model.state_dict(), path)\n\n    def train(self, num_epochs: int):\n        model = self.model\n        optimizer = self.optimizer\n        \n        if self.train_sampler is None:\n            shuffle=True\n        else:\n            shuffle=False\n        train_loader = DataLoader(self.train_dataset, pin_memory=True, shuffle=shuffle, batch_size=self.batch_size, sampler=self.train_sampler)\n        val_loader = DataLoader(self.val_dataset, pin_memory=True, shuffle=False, batch_size=self.batch_size, sampler=self.val_sampler)\n        best_loss = float('inf')\n\n        for epoch in range(num_epochs):\n            model.train()\n            for batch in tqdm(train_loader):\n                batch = {k: v.to(self.device) for k, v in batch.items()}\n                loss, details = model.compute_all(batch)\n\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n                \n                for k, v in details.items():\n                    self.train_writer.add_scalar(k, v, global_step=self.global_step)\n            \n                self.train_writer.add_scalar(f'loss', loss, global_step=self.global_step)\n                self.global_step += 1\n    \n\n            model.eval()\n            val_losses, val_metrics_list = [], []\n                \n            for batch in tqdm(val_loader):\n                batch = {k: v.to(self.device) for k, v in batch.items()}\n                loss, details = model.compute_all(batch)\n                val_losses.append(loss.item())\n                val_metrics_list.append(details['acc'].item())\n                                  \n            val_loss = np.mean(val_losses)\n            val_metrics = np.mean(val_metrics_list)\n\n            self.val_writer.add_scalar(f'loss', val_loss, global_step=self.global_step)\n            self.val_writer.add_scalar(f'metrics', val_metrics, global_step=self.global_step)\n\n            if val_loss < best_loss:\n                self.save_checkpoint(\"./best_checkpoint.pth\")\n                best_loss = val_loss\n                                  \n            print('[{} epoch] - loss: {}, metric: {}'.format(epoch+1, round(val_loss, 5), round(val_metrics, 5)))\n            \n    def find_lr(self, min_lr: float = 1e-6,\n                max_lr: float = 1e-1,\n                num_lrs: int = 20,\n                smooth_beta: float = 0.8) -> dict:\n        lrs = np.geomspace(start=min_lr, stop=max_lr, num=num_lrs)\n        logs = {'lr': [], 'loss': [], 'avg_loss': []}\n        avg_loss = None\n        model, optimizer = self.model, self.optimizer\n        \n        train_loader = DataLoader(self.train_dataset, pin_memory=True, shuffle=False, batch_size=self.batch_size, sampler=self.train_sampler)\n\n        model.train()\n        for lr, batch in tqdm(zip(lrs, train_loader), desc='finding LR', total=num_lrs):\n            # apply new lr\n            for param_group in self.optimizer.param_groups:\n                param_group['lr'] = lr\n\n            # train step\n            batch = {k: v.to(self.device) for k, v in batch.items()}\n            loss, details = model.compute_all(batch)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            # calculate smoothed loss\n            if avg_loss is None:\n                avg_loss = loss\n            else:\n                avg_loss = smooth_beta * avg_loss + (1 - smooth_beta) * loss\n\n            # store values into logs\n            logs['lr'].append(lr)\n            logs['avg_loss'].append(avg_loss)\n            logs['loss'].append(loss)\n            \n        for k, v in logs.items():\n            for i in range(len(v)):\n                self.train_writer.add_scalar(k, v[i], global_step=self.global_step)\n                self.global_step += 1\n\n        logs.update({key: np.array(val) for key, val in logs.items()})\n        self.rollback_states()\n\n        return logs\n\n    def cache_states(self):\n        cache_dict = {'model_state': deepcopy(self.model.state_dict()),\n                      'optimizer_state': deepcopy(self.optimizer.state_dict())}\n\n        return cache_dict\n\n    def rollback_states(self):\n        self.model.load_state_dict(self.cache['model_state'])\n        self.optimizer.load_state_dict(self.cache['optimizer_state'])","metadata":{"cellId":"bygg4qs7xeoygheo4nuzu","trusted":true},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"Натренируем разные модели, та, которая покажет наименьший лосс, ту и возьмем в следующих заданиях.","metadata":{"cellId":"if4vmv67q6fhruk79sbvlj"}},{"cell_type":"code","source":"#!g1.1\nRNN = NameRNN(len(tokens), 500, len(tokens), cell='rnn')\nopt = torch.optim.Adam(RNN.parameters(), lr=1e-4)\ntrainer = Trainer(model = RNN, optimizer = opt, train_dataset = trainset, \n                  val_dataset = valset, batch_size=16)","metadata":{"cellId":"1444fiusjv789t041dulg7m","trusted":true},"outputs":[{"output_type":"stream","name":"stderr","text":"/kernel/lib/python3.7/site-packages/ml_kernel/kernel.py:811: UserWarning: The following variables cannot be serialized: trainer\n  warnings.warn(message)\n"}],"execution_count":16},{"cell_type":"code","source":"#!g1.1\ntrainer.train(5)","metadata":{"cellId":"5cj3x8nddsx9ami3nkvjne","trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=403.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d487c75fd9ad4f30a2ba4cdb1dab7a2f"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=72.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5cf369dd561c4c9da3365e5fcd6f7a1b"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n[1 epoch] - loss: 17.09869, metric: 0.26666\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=403.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"307fca430abf4fd389910c66c897c617"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=72.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"723755ecbd8242fe88be8dbcf05665d7"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n\n[2 epoch] - loss: 16.73139, metric: 0.26622\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=403.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6848cf93df5459da58ce001b154f70b"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=72.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1dbc7d54107a4b1584660b1bfc4ed669"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n[3 epoch] - loss: 16.63686, metric: 0.26785\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=403.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"749e101d5fee426ebf50ad38afef5efb"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=72.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ccfa5bd487a4e0fae7155acbfa6c45c"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n[4 epoch] - loss: 16.60099, metric: 0.26666\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=403.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0297985683894ac78c2c6250d57ecb0e"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=72.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3e6f634762d4a1e9dab608f5579c666"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n[5 epoch] - loss: 16.58045, metric: 0.26823\n"},{"output_type":"stream","name":"stderr","text":"/kernel/lib/python3.7/site-packages/ml_kernel/kernel.py:811: UserWarning: The following variables cannot be serialized: trainer\n  warnings.warn(message)\n"}],"execution_count":17},{"cell_type":"code","source":"#!g1.1\nLSTM = NameRNN(len(tokens), 500, len(tokens), cell='lstm')\nopt = torch.optim.Adam(LSTM.parameters(), lr=1e-4)\ntrainer = Trainer(model = LSTM, optimizer = opt, train_dataset = trainset, \n                  val_dataset = valset, batch_size=16)","metadata":{"cellId":"5tyogkid3xadbapzm78xgp","trusted":true},"outputs":[{"output_type":"stream","name":"stderr","text":"/kernel/lib/python3.7/site-packages/ml_kernel/kernel.py:811: UserWarning: The following variables cannot be serialized: trainer\n  warnings.warn(message)\n"}],"execution_count":18},{"cell_type":"code","source":"#!g1.1\ntrainer.train(5)","metadata":{"cellId":"l94zxn0errb9rloyqkf35","trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=403.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e52b251fa1a4b1baed976f543e93b20"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=72.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ddd407847fb149adbd4ef907f4fe6cd2"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n[1 epoch] - loss: 17.46073, metric: 0.26584\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=403.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d76341f3cdf45cf9a13230be955251d"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=72.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c95194cc557e4264b319faa6972919ce"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n[2 epoch] - loss: 16.85908, metric: 0.26736\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=403.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d591e83bdb99477e8a202836f562dafe"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=72.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d6ea4fde51d4aefb4d57494a4f5af93"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n[3 epoch] - loss: 16.68001, metric: 0.26769\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=403.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ada7413903a04792a0cbac486fd9a9e9"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=72.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b912f4c6a3f84ee89b4882c98b635019"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n[4 epoch] - loss: 16.61956, metric: 0.26666\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=403.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fcc2983264164bd08002c71dde3cda21"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=72.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd7b7097bc084af0b99ee88bbb49e975"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n[5 epoch] - loss: 16.57081, metric: 0.26617\n"},{"output_type":"stream","name":"stderr","text":"/kernel/lib/python3.7/site-packages/ml_kernel/kernel.py:811: UserWarning: The following variables cannot be serialized: trainer\n  warnings.warn(message)\n"}],"execution_count":19},{"cell_type":"code","source":"#!g1.1\nGRU = NameRNN(len(tokens), 500, len(tokens), cell='gru')\nopt = torch.optim.Adam(GRU.parameters(), lr=1e-4)\ntrainer = Trainer(model = GRU, optimizer = opt, train_dataset = trainset, \n                  val_dataset = valset, batch_size=16)","metadata":{"cellId":"dryjtacprt8oz7dfcy0yrp","trusted":true},"outputs":[{"output_type":"stream","name":"stderr","text":"/kernel/lib/python3.7/site-packages/ml_kernel/kernel.py:811: UserWarning: The following variables cannot be serialized: trainer\n  warnings.warn(message)\n"}],"execution_count":20},{"cell_type":"code","source":"#!g1.1\ntrainer.train(5)","metadata":{"cellId":"4edt29h523fjauhctiu0w","trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=403.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba943005c3aa4c32ac7bbdc791f41a7d"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=72.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c955fa378a4450d83e92b038feb12e1"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n[1 epoch] - loss: 17.19627, metric: 0.26617\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=403.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1bc098bcf8774ca7ae1bff2722174fd3"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=72.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9cd1911921464439ab205386c6cf2e8f"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n[2 epoch] - loss: 16.76662, metric: 0.26503\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=403.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"890eecab862543b6920dfe6482849f03"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=72.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"608d94b5827448ccaef797620c09b047"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n[3 epoch] - loss: 16.64545, metric: 0.2672\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=403.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a71fc9a94d14bfc855f3f463c027f11"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=72.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4df668aed32149a0b8d553450d62290e"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n[4 epoch] - loss: 16.59138, metric: 0.26921\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=403.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9d0f683cf2c4e94830359239f47389d"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=72.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7883b36e307e4ae18354d13f1b55a6de"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n[5 epoch] - loss: 16.57261, metric: 0.26812\n"},{"output_type":"stream","name":"stderr","text":"/kernel/lib/python3.7/site-packages/ml_kernel/kernel.py:811: UserWarning: The following variables cannot be serialized: trainer\n  warnings.warn(message)\n"}],"execution_count":21},{"cell_type":"markdown","source":"Дополнительно натренеруем \"лучшую\" модель. (Они оказались +- одинаковыми, остановимся на RNN)","metadata":{"cellId":"8q5bhw7taknaz6nuz68gnc"}},{"cell_type":"code","source":"#!g1.1\nopt = torch.optim.Adam(RNN.parameters(), lr=1e-4)\ntrainer = Trainer(model = RNN, optimizer = opt, train_dataset = trainset, \n                  val_dataset = valset, batch_size=16)","metadata":{"cellId":"04w99marpsvbydnyj57zfch","trusted":true},"outputs":[{"output_type":"stream","name":"stderr","text":"/kernel/lib/python3.7/site-packages/ml_kernel/kernel.py:811: UserWarning: The following variables cannot be serialized: trainer\n  warnings.warn(message)\n"}],"execution_count":22},{"cell_type":"code","source":"#!g1.1\ntrainer.train(10)","metadata":{"cellId":"uyyw3zuwpxhu9qpfod0ap","trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=403.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"accfcf0f85bf4e13a836edfaf9bc379b"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=72.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04bdc6cdc6324fc5a701a38b78c88534"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n[1 epoch] - loss: 16.5441, metric: 0.2672\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=403.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ba9b881587d4ba481a1718897721cc3"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=72.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"add9cecaeea94696b6dacee49f2bf14e"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n[2 epoch] - loss: 16.57162, metric: 0.26774\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=403.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"78b9d8000d2d4e4191c383e496363df9"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=72.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0baec2be0e64508bc9aa6b90eb286ab"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n[3 epoch] - loss: 16.5466, metric: 0.26769\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=403.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d386784f9e624b1fb341256f5a7e3b75"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=72.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e6395984e2b40e38d512a84b572ab9a"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n[4 epoch] - loss: 16.54046, metric: 0.2685\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=403.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f20c0cccced4e98a3bf50bc4baf6796"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=72.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ec72a4fd3ea47449db004917f30ff4a"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n[5 epoch] - loss: 16.55406, metric: 0.26872\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=403.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85c3e16b9ce64cfdbb29a829584a6e5f"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=72.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"319bacbd5c9c4e81a33a5eb4296c6973"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n[6 epoch] - loss: 16.55259, metric: 0.26682\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=403.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a15991c0f6946c4915e21ca5dbcc4e5"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=72.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd89c85478994765861dc4abce462f45"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n[7 epoch] - loss: 16.51213, metric: 0.26666\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=403.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a2c21ae2c204d15831749289e35794f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=72.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c988f32fd364d818e3d33d2e6291770"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n\n[8 epoch] - loss: 16.54277, metric: 0.26617\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=403.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f7a06687b4f3437aaed71dc4ded87947"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=72.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7176c234ecc4414a84ffc787336a34e"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n[9 epoch] - loss: 16.53426, metric: 0.26617\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=403.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10fac3a1a4274b359bafeb06b82c9b68"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=72.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff29cf6d33b54259832df6ce235914d2"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":"\n[10 epoch] - loss: 16.53237, metric: 0.26454\n"},{"output_type":"stream","name":"stderr","text":"/kernel/lib/python3.7/site-packages/ml_kernel/kernel.py:811: UserWarning: The following variables cannot be serialized: trainer\n  warnings.warn(message)\n"}],"execution_count":23},{"cell_type":"markdown","source":"# Генерация по argmax (0.2 балла)","metadata":{"id":"ffTAktWAIaP5","cellId":"yhg4bqk3oznk5iwfr8ywk"}},{"cell_type":"code","source":"#!g1.1\n# Напишите функцию генерации продолжения строки\ndef pick_by_argmax(logits):\n    return logits.cpu().argmax(axis=1).numpy()[0]\n\ndef ids2string(ids):\n    return \"\".join(id2tok[_] for _ in ids)\n\n\ndef gen_continuation(model, prefix=\"_\"):\n    # TODO: сначала подайте на вход префикс\n    # нас интересует последний output, чтобы получить первое предсказание\n    hidden = model.init_hidden(1)\n    lst = []\n    for letter in prefix:\n        lst.append(tok2id[letter])\n    prefix_tensor = torch.tensor(lst).view(-1, 1).cuda()\n    for i in prefix_tensor:\n        out, hidden = model.forward(i, hidden)\n    # TODO: затем сгенерируйте несколько последующих символов\n    # outs -- это массив с номерами токенов\n    outs = [pick_by_argmax(out)]\n    ids = out.argmax(axis=1)\n    for i in range(8): # в зависимости от максимальной длины имени, моя модель видила имена максю длины - 10\n        out, hidden = model.forward(ids, hidden)\n        outs.append(pick_by_argmax(out))\n        ids = out.argmax(axis=1)\n    \n    print(prefix + '|'+ ids2string(outs))\n    \ngen_continuation(RNN, \"_Ku\")","metadata":{"id":"ugRlkX2ZIaP6","cellId":"z4hzc1p1ppj1ap23djh6dk","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"_Ku|rin#     \n"},{"output_type":"stream","name":"stderr","text":"/kernel/lib/python3.7/site-packages/ml_kernel/kernel.py:811: UserWarning: The following variables cannot be serialized: trainer\n  warnings.warn(message)\n"}],"execution_count":24},{"cell_type":"markdown","source":"# Генерация с семплированием (0.2 балла)\n\nОбычный софтмакс \n$$p_i = \\frac{\\exp (x_i)}{\\sum \\exp (x_j)}$$\nможно модернизировать с помощью температуры:\n$$p_i = \\frac{\\exp (x_i / T)}{\\sum \\exp (x_j / T)}$$\n\nЭто позволит плавно переходить от выбора наиболее вероятного элемента ($T << 1$) до практически равновероятного ($T >> 1$)\n","metadata":{"id":"00547AA-IaP_","cellId":"21eew1ri4b8ofrdwk5se7"}},{"cell_type":"code","source":"#!g1.1\n# Напишите функцию генерации батчами с семплированием из распределения и температурой\ndef batch2string(ids, prefix):\n    # модифицируйте ids2string для работы с батчами\n    return '\\n'.join([prefix + ''.join(id2tok[_] for _ in x) for x in ids])\n\ndef pick_by_distribution(logits, temperature):\n    # превратите логиты в распределение\n    # затем семлируйте из него batch примеров\n    logits=logits.cpu()\n    distr = torch.exp(logits / temperature) / torch.sum(torch.exp(logits / temperature))\n    return np.random.choice(range(len(distr)), size=1, p=distr.detach().numpy())[0]\n\n\ndef gen_continuation_temp(model, prefix=\"_\", temperature=1.0, n=10):\n    # аналогично, сначала подайте на вход префикс\n    # нас интересует последний output, чтобы получить первое предсказание\n    hidden = model.init_hidden(n)\n    lst = []\n    for letter in prefix:\n        lst.append(tok2id[letter])\n    prefix_tensor = torch.tensor(lst).view(-1, 1) \n    prefix_tensor = prefix_tensor.repeat(1, n).cuda()\n    for i in prefix_tensor:\n        out, hidden = model.forward(i, hidden)\n    # затем, сгенерируйте n последующих символов\n    # в outs положите матрицу номеров токенов и отобразите ее\n    outs = []\n    for i in range(n):\n        outs.append([pick_by_distribution(out[i], temperature)])\n    ids = torch.tensor(outs).cuda()\n    for i in range(8): # в зависимости от максимальной длины имени, моя модель видила имена максю длины - 10\n        out, hidden = model.forward(ids, hidden)\n        for j in range(n):\n            outs[j].append(pick_by_distribution(out[j], temperature))\n        ids = torch.tensor(outs)[:, i + 1].cuda()\n    \n    print(batch2string(outs, prefix + '|'))\n    \ngen_continuation_temp(RNN, prefix=\"_An\", temperature=0.5, n=10)","metadata":{"id":"71cOcFxpIaQA","cellId":"6ye146zddiec7fi33zz5ul","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"_An|donne#   \n_An|ery#     \n_An|#        \n_An|nia#     \n_An|a#       \n_An|ale#     \n_An|#        \n_An|#        \n_An|#        \n_An|in#      \n"},{"output_type":"stream","name":"stderr","text":"/kernel/lib/python3.7/site-packages/ml_kernel/kernel.py:811: UserWarning: The following variables cannot be serialized: trainer\n  warnings.warn(message)\n"}],"execution_count":25},{"cell_type":"markdown","source":"# Char-Transformer для имен (1.0 дополнительные баллы)\n\nВам нужно написать сеть, кодирующую входные символы и их позиции с помощью таблиц Embeddings. \nПолучившиеся тензоры пропустить через `TransformerEncoder`, затем преобразовать в логиты для предсказания новых символов.\n\nTransformer может обрабатывать сразу всю последовательность за один проход. Для того, чтобы у модели не было возможности \"заглянуть в будущее\", то есть использовать информацию о впреди идущих символах, необходимо сгенерировать маску. `TransformerEncoder` должен принимать на вход последовательность символов и маску.    \n![Transformer](https://drive.google.com/uc?export=view&id=1gXILzT3mGgc0mGlvqY-6R4bGs3Lx2YxM)\nКартинка из [illustrated transformer](http://jalammar.github.io/illustrated-transformer/)","metadata":{"id":"NhgqoEHOIaPr","cellId":"ggg9m9eb4bjmgwebowpml"}},{"cell_type":"code","source":"# TODO: заполните пропуски\n\nclass NameTransformer(nn.Module):\n    def __init__(self, vocab_size, emb_size, hidden_size, n_layers=2, n_head=2, dropout=0.1):\n        super(NameTransformer, self).__init__()\n        self.vocab_size = vocab_size\n\n        <your code>\n\n    def _generate_square_subsequent_mask(self, seq_len):\n        # TODO: сгенерируйте маску размера seq_len x seq_len\n        # если во время кодирования i-го символа j-й символ доступен, \n        # то (i,j) элемент маски равен 0, иначе -inf\n        \n        <your code>\n\n        return mask\n        \n    def forward(self, input):\n\n        <your code>\n\n        return output","metadata":{"id":"KJCf0LYIIaPt","cellId":"devnd4kux699h066amnwk9"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Натренируйте модель\n\nИ убедитесь, что она работает адекватно","metadata":{"id":"BmkgMHc8IaPu","cellId":"eweqz6m81mrgcd7b0xt92b"}},{"cell_type":"code","source":"","metadata":{"id":"Sxrc0a10IaPy","cellId":"8sgl7gpgw95zsccy68954q"},"outputs":[],"execution_count":null}]}